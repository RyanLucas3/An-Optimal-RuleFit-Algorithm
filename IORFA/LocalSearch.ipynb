{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# sys.path.append(\"..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gurobipy\n",
    "import pandas as pd\n",
    "from IORFA import *\n",
    "import numpy as np\n",
    "import time\n",
    "from sklearn.metrics import r2_score\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.tree import export_text\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.5\n",
    "val_ratio = 0.25\n",
    "test_ratio = 0.25\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "## Create artificial data set with\n",
    "n = 500\n",
    "x1 = np.random.normal(loc = 0,scale=1, size=n)\n",
    "x2 = np.random.normal(loc=0, scale=1, size=n)\n",
    "x3 = np.random.normal(loc=0, scale=1, size=n)\n",
    "x4 = np.random.normal(loc=0, scale=1, size=n)\n",
    "x5 = np.random.normal(loc =0,scale=1, size=n)\n",
    "x6 = np.random.normal(loc=0, scale=1, size=n)\n",
    "x7 = np.random.normal(loc=0, scale=1, size=n)\n",
    "x8 = np.random.normal(loc=0, scale=1, size=n)\n",
    "\n",
    "simulated_data = pd.DataFrame({'x1': x1, 'x2': x2, 'x3': x3, 'x4': x4, \n",
    "                                'x5': x5, 'x6': x6, 'x7': x7, 'x8': x8})\n",
    "\n",
    "x = simulated_data[[f'x{i}' for i in range(1, 9)]]\n",
    "\n",
    "orig_cols = simulated_data.columns\n",
    "\n",
    "# Create an instance of the MinMaxScaler\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "\n",
    "# Assuming you have a feature matrix X\n",
    "# Apply the min-max scaling to the data\n",
    "x = scaler.fit_transform(x)\n",
    "\n",
    "y = 0.2*(x[:, 0] > 0.2)*(x[:, 5] < 0.5) + 0.3*x[:, 3]\n",
    "\n",
    "y_bar = y\n",
    "\n",
    "y = y_bar\n",
    "\n",
    "x = np.array(x)\n",
    "y = np.array(y)\n",
    "\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=1-train_ratio, random_state=seed)\n",
    "x_val, x_test, y_val, y_test = train_test_split(x_test, y_test, \n",
    "                                                test_size=test_ratio/(test_ratio+val_ratio), random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = pd.DataFrame(x_train, columns = orig_cols)\n",
    "x_test = pd.DataFrame(x_test, columns = orig_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "DecisionTreeRegressor(max_depth=2)",
      "text/html": "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeRegressor(max_depth=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeRegressor</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeRegressor(max_depth=2)</pre></div></div></div></div></div>"
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "T = DecisionTreeRegressor(max_depth=2)\n",
    "T.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tree Rules:\n",
      "|--- x6 <= 0.50\n",
      "|   |--- x4 <= 0.51\n",
      "|   |   |--- value: [0.31]\n",
      "|   |--- x4 >  0.51\n",
      "|   |   |--- value: [0.39]\n",
      "|--- x6 >  0.50\n",
      "|   |--- x4 <= 0.56\n",
      "|   |   |--- value: [0.12]\n",
      "|   |--- x4 >  0.56\n",
      "|   |   |--- value: [0.21]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract the rules from the decision tree\n",
    "tree_rules = export_text(T, feature_names=list(orig_cols))\n",
    "\n",
    "print(\"Tree Rules:\")\n",
    "print(tree_rules)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def parse_tree_rules(tree_rules_str):\n",
    "    lines = tree_rules_str.split(\"\\n\")\n",
    "    rules = []\n",
    "    conditions = []\n",
    "\n",
    "    for line in lines:\n",
    "        if '---' in line:\n",
    "            # Determine the level of the current condition by counting the leading '|'\n",
    "            level = line.count(\"|\", 0, line.index(\"---\"))\n",
    "            # Extract variable, operator, and value\n",
    "            match = re.search(r\"(x\\d+)\\s*([<>=]+)\\s*([\\d\\.]+)\", line)\n",
    "            if match:\n",
    "                var, op, value = match.groups()\n",
    "\n",
    "                print(var, op, value)\n",
    "\n",
    "                # Adjust the size of conditions list to match the current level\n",
    "                conditions = conditions[:level]\n",
    "                print()\n",
    "                conditions.append(f\"({var} {op} {value})\")\n",
    "\n",
    "        elif 'value:' in line:\n",
    "            # Extract value\n",
    "            value = re.findall(r\"\\[([\\d\\.]+)\\]\", line)[0]\n",
    "            # Combine conditions to a single string and append to rules\n",
    "            rule = \" & \".join(conditions)\n",
    "            rules.append((rule, float(value)))\n",
    "\n",
    "    return conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x6 <= 0.50\n",
      "\n",
      "x4 <= 0.51\n",
      "\n",
      "x4 > 0.51\n",
      "\n",
      "x6 > 0.50\n",
      "\n",
      "x4 <= 0.56\n",
      "\n",
      "x4 > 0.56\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "['(x6 <= 0.50)', '(x6 > 0.50)', '(x4 > 0.56)']"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_tree_rules(tree_rules)\n",
    "InitialSteps(x_train, y_train, 3, alpha = 0.00001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import _tree\n",
    "\n",
    "def get_rules(tree, feature_names, class_names):\n",
    "    tree_ = tree.tree_\n",
    "    feature_name = [\n",
    "        feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "        for i in tree_.feature\n",
    "    ]\n",
    "\n",
    "    paths = []\n",
    "    path = []\n",
    "    \n",
    "    def recurse(node, path, paths):\n",
    "        \n",
    "        if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "            name = feature_name[node]\n",
    "            threshold = tree_.threshold[node]\n",
    "            p1, p2 = list(path), list(path)\n",
    "            p1 += [f\"({name} <= {np.round(threshold, 3)})\"]\n",
    "            recurse(tree_.children_left[node], p1, paths)\n",
    "            p2 += [f\"({name} > {np.round(threshold, 3)})\"]\n",
    "            recurse(tree_.children_right[node], p2, paths)\n",
    "        else:\n",
    "            path += [(tree_.value[node], tree_.n_node_samples[node])]\n",
    "            paths += [path]\n",
    "            \n",
    "    recurse(0, path, paths)\n",
    "\n",
    "    # sort by samples count\n",
    "    samples_count = [p[-1][1] for p in paths]\n",
    "    ii = list(np.argsort(samples_count))\n",
    "    print(samples_count)\n",
    "    paths = [paths[i] for i in reversed(ii)]\n",
    "    \n",
    "    rules = []\n",
    "    for path in paths:\n",
    "        rule = \"\"\n",
    "        \n",
    "        for p in path[:-1]:\n",
    "            if rule != \"\":\n",
    "                rule += \" & \"\n",
    "            rule += str(p)\n",
    "\n",
    "        rules += [rule]\n",
    "        \n",
    "    return rules\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objective function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "# Algo 8.1 LocalSearch\n",
    "\n",
    "def InitialSteps(X, y, max_depth, alpha):\n",
    "\n",
    "    X = X.copy()\n",
    "\n",
    "    T = DecisionTreeRegressor(max_depth=max_depth)\n",
    "    T.fit(x_train, y_train)\n",
    "\n",
    "    rules = get_rules(T, list(orig_cols), None)\n",
    "    for i, rule in enumerate(rules):\n",
    "        X[f'rule_{i}'] = X.eval(rule).astype(int)\n",
    "    \n",
    "    rulefit = LinearRegression()\n",
    "    rulefit.fit(X, y) # rulefit is LinReg because we added rules already :D\n",
    "    SSE = mean_squared_error(rulefit.predict(X), y)\n",
    "\n",
    "    ####### Needed to define Loss(T, X, y) ######\n",
    "    is_leaf = np.logical_and(T.tree_.children_left == -1, T.tree_.children_right == -1)\n",
    "    d = np.count_nonzero(~is_leaf) # recall complexity d is |T| = number of branching nodes (not 2^max_depth)\n",
    "    ######\n",
    "\n",
    "    n = y.shape[0]\n",
    "    L_init = SSE*n + alpha*d\n",
    "\n",
    "    print(f\"SSE contributes {SSE*n*100/L_init}% to the initial loss\")\n",
    "    print(f\"Complexity contributes {alpha*d*100/L_init}%\")\n",
    "\n",
    "    return L_init"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE contributes 1.2360291662818856e-23% to the initial loss\n",
      "Complexity contributes 100.0%\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "7.000000000000001e-05"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes(T):\n",
    "\n",
    "    lc = list(T.tree_.children_left)\n",
    "    rc = list(T.tree_.children_right)\n",
    "\n",
    "    nodes = [0] + lc + rc # nodes are root + left children + right_children\n",
    "    nodes = list(set(nodes)) # but some children can be duplicates\n",
    "    nodes = np.setdiff1d(nodes, np.array(-1)) # also -1 is not a node but indicates a node doesn't exist\n",
    "\n",
    "    return nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle(arr):\n",
    "    # need a fn for this because np.random.shuffle is not inplace\n",
    "    arr_copy = arr.copy()\n",
    "    np.random.shuffle(arr_copy)\n",
    "    return arr_copy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_leaf_nodes(T, t):\n",
    "    # List to store the leaf nodes\n",
    "    leaf_nodes = []\n",
    "\n",
    "    # Recursive helper function\n",
    "    def explore(node):\n",
    "        # If this is a leaf node, add it to the list\n",
    "        if T.tree_.children_left[node] == T.tree_.children_right[node] == -1:\n",
    "            leaf_nodes.append(node)\n",
    "        \n",
    "        else:\n",
    "            # If this is a branch node, explore its children\n",
    "            if T.tree_.children_left[node] != -1:\n",
    "                explore(T.tree_.children_left[node])\n",
    "            if T.tree_.children_right[node] != -1:\n",
    "                explore(T.tree_.children_right[node])\n",
    "\n",
    "    # Start exploring from node t\n",
    "    explore(t)\n",
    "\n",
    "    return leaf_nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_I(T, X, nodes_in_T_t):\n",
    "\n",
    "    belongs_to = T.apply(X) # leaf node obs belong to\n",
    "\n",
    "    I = []\n",
    "\n",
    "    for i in range(X.shape[0]):\n",
    "\n",
    "        if belongs_to[i] in nodes_in_T_t:\n",
    "\n",
    "            I.append(i) \n",
    "    \n",
    "    return I"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def OptimizeNodeParallel(self, id, X_I, y_I):\n",
    "\n",
    "    left_child, right_child = self.find_children(id)\n",
    "\n",
    "    if left_child != -1 or right_child != -1: # not leaf\n",
    "\n",
    "        T_para, error_para = self.BestParallelSplit(id, left_child,\n",
    "                                                    right_child,\n",
    "                                                    X_I,\n",
    "                                                    y_I)\n",
    "\n",
    "    else:\n",
    "\n",
    "    if error_para\n",
    "\n",
    "\n",
    "def BestParallelSplit(self, id,\n",
    "                      left_child,\n",
    "                      right_child,\n",
    "                      X_I,\n",
    "                      y_I):\n",
    "\n",
    "    n, p = X_I.shape\n",
    "    error_best = np.inf\n",
    "    tree_mod = T.copy()\n",
    "\n",
    "    for j in range(p):\n",
    "\n",
    "        values = X_I[:, j]\n",
    "        values = sorted(values)\n",
    "\n",
    "        for i in range(0, n):\n",
    "\n",
    "            b = (1/2)*(values[i] + values[i+1])\n",
    "\n",
    "            # For the jth feature, get all rows where the feature is greater than b\n",
    "            higher_than_b = X_I[:, j] > b\n",
    "\n",
    "            # And where it's lower than or equal to b\n",
    "            lower_or_equal_to_b = X_I[:, j] <= b\n",
    "            X_I_higher = X_I[higher_than_b]\n",
    "\n",
    "            X_I_lower = X_I[lower_or_equal_to_b]\n",
    "\n",
    "            if len(X_I_higher) > self.min_leaf_size and len(X_I_lower) > self.min_leaf_size:\n",
    "\n",
    "                tree_mod.tree_.feature[id] = j\n",
    "                tree_mod.tree_.threshold[id] = b\n",
    "                rules = get_rules(tree_mod, list(orig_cols), None)\n",
    "                for i, rule in enumerate(rules):\n",
    "                    self.X[f'rule_{i}'] = self.X.eval(rule).astype(int)\n",
    "\n",
    "                rulefit = LinearRegression()\n",
    "                rulefit.fit(self.X, self.y) # rulefit is LinReg because we added rules already :D\n",
    "                SSE = mean_squared_error(rulefit.predict(self.X), self.y)\n",
    "\n",
    "                if SSE < error_best:\n",
    "                    error_best = SSE\n",
    "                    best_tree = tree_mod\n",
    "        return best_tree, error_best\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                # Calculate loss and update error if current error is lower than error_best\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_children(self, id):\n",
    "\n",
    "    left_child_cand = [i for i in self.T.tree_.children_left if i > id]\n",
    "    right_child_cand  = [i for i in self.T.tree_.children_right if i > id]\n",
    "\n",
    "    left_children = list(set(left_child_cand))\n",
    "    right_children = list(set(right_child_cand))\n",
    "\n",
    "    if len(left_children) == 0:\n",
    "        left_children = [-1]\n",
    "    \n",
    "    if len(right_children) == 0:\n",
    "        right_children = [-1]\n",
    "    \n",
    "    return min(left_children), min(right_children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LocalSearch(T, X, y, max_depth):\n",
    "    \n",
    "    # Extracting initial loss\n",
    "    error_prev = InitialSteps(X, y, max_depth, alpha = 0.00001)\n",
    "    \n",
    "    X = np.array(X)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    for t in shuffle(nodes(T)):\n",
    "\n",
    "        nodes_in_T_t = find_leaf_nodes(T, t)\n",
    "\n",
    "        I = construct_I(T, X, nodes_in_T_t)\n",
    "\n",
    "        T_t = OptimizeNodeParallel(T_t, X[I], y[I])\n",
    "\n",
    "        \n",
    "\n",
    "        # Replace tth node in T with T_t\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import _tree, DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "class RuleFitLocalSearch:\n",
    "    def __init__(self, max_depth=5, min_leaf_size=5, alpha=0.00001):\n",
    "        self.max_depth = max_depth\n",
    "        self.min_leaf_size = min_leaf_size\n",
    "        self.alpha = alpha\n",
    "        self.X = None\n",
    "        self.y = None\n",
    "        self.T = None\n",
    "        self.error_cur = np.inf\n",
    "        self.error_prev = None\n",
    "\n",
    "    def initial_steps(self):\n",
    "        rules = self.get_rules(list(self.X.columns))\n",
    "        for i, rule in enumerate(rules):\n",
    "            self.X[f'rule_{i}'] = self.X.eval(rule).astype(int)\n",
    "\n",
    "        rulefit = LinearRegression()\n",
    "        rulefit.fit(self.X, self.y)\n",
    "        SSE = mean_squared_error(rulefit.predict(self.X), self.y)\n",
    "\n",
    "        n = self.y.shape[0]\n",
    "        L_init = SSE*n + self.alpha*len(self.nodes())\n",
    "\n",
    "        print(f\"SSE contributes {SSE*n*100/L_init}% to the initial loss\")\n",
    "        print(f\"Complexity contributes {self.alpha*len(self.nodes())*100/L_init}%\")\n",
    "        return L_init\n",
    "\n",
    "    def nodes(self):\n",
    "        lc = list(self.T.tree_.children_left)\n",
    "        rc = list(self.T.tree_.children_right)\n",
    "\n",
    "        nodes = [0] + lc + rc\n",
    "        nodes = list(set(nodes))\n",
    "        nodes = [i for i in nodes if i != -1]\n",
    "        return nodes\n",
    "\n",
    "    def find_leaf_nodes(self, t):\n",
    "        leaf_nodes = []\n",
    "        def explore(node):\n",
    "            if self.T.tree_.children_left[node] == self.T.tree_.children_right[node] == -1:\n",
    "                leaf_nodes.append(node)\n",
    "            else:\n",
    "                if self.T.tree_.children_left[node] != -1:\n",
    "                    explore(self.T.tree_.children_left[node])\n",
    "                if self.T.tree_.children_right[node] != -1:\n",
    "                    explore(self.T.tree_.children_right[node])\n",
    "        explore(t)\n",
    "        return leaf_nodes\n",
    "\n",
    "    def construct_I(self, X, nodes_in_T_t):\n",
    "        belongs_to = self.T.apply(X)\n",
    "        I = [i for i in range(X.shape[0]) if belongs_to[i] in nodes_in_T_t]\n",
    "        return I\n",
    "\n",
    "    def find_children(self, id):\n",
    "        left_child_cand = [i for i in self.T.tree_.children_left if i > id]\n",
    "        right_child_cand  = [i for i in self.T.tree_.children_right if i > id]\n",
    "\n",
    "        left_children = list(set(left_child_cand))\n",
    "        right_children = list(set(right_child_cand))\n",
    "\n",
    "        if len(left_children) == 0:\n",
    "            left_children = [-1]\n",
    "\n",
    "        if len(right_children) == 0:\n",
    "            right_children = [-1]\n",
    "\n",
    "        return min(left_children), min(right_children)\n",
    "\n",
    "    def optimize_node_parallel(self, id, X_I, y_I):\n",
    "        left_child, right_child = self.find_children(id)\n",
    "        if left_child != -1 or right_child != -1: # not leaf\n",
    "            T_para, error_para = self.best_parallel_split(id, left_child, right_child, X_I, y_I)\n",
    "        # else:\n",
    "        #     # TODO: Define what happens if the node is a leaf.\n",
    "\n",
    "        if self.error_cur > error_para:\n",
    "            self.T = T_para\n",
    "            self.error_cur = error_para\n",
    "\n",
    "\n",
    "    def best_parallel_split(self, id, left_child, right_child, X_I, y_I):\n",
    "        n, p = X_I.shape\n",
    "        error_best = np.inf\n",
    "        tree_mod = self.T\n",
    "        for j in range(p):\n",
    "            values = np.sort(X_I[:, j])\n",
    "            for i in range(n-1):\n",
    "                b = (values[i] + values[i+1]) / 2\n",
    "                higher_than_b = X_I[:, j] > b\n",
    "                lower_or_equal_to_b = X_I[:, j] <= b\n",
    "                X_I_higher = X_I[higher_than_b]\n",
    "                X_I_lower = X_I[lower_or_equal_to_b]\n",
    "                if len(X_I_higher) > self.min_leaf_size and len(X_I_lower) > self.min_leaf_size:\n",
    "                    tree_mod.tree_.feature[id] = j\n",
    "                    tree_mod.tree_.threshold[id] = b\n",
    "                    rules = self.get_rules(tree_mod, list(self.X.columns), None)\n",
    "                    for i, rule in enumerate(rules):\n",
    "                        self.X[f'rule_{i}'] = self.X.eval(rule).astype(int)\n",
    "                    rulefit = LinearRegression()\n",
    "                    rulefit.fit(self.X, self.y)\n",
    "                    SSE = mean_squared_error(rulefit.predict(self.X), self.y)\n",
    "                    if SSE < error_best:\n",
    "                        error_best = SSE\n",
    "                        best_tree = tree_mod\n",
    "        return best_tree, error_best\n",
    "\n",
    "    def local_search(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.T = DecisionTreeRegressor(max_depth=self.max_depth).fit(self.X, self.y)\n",
    "\n",
    "        while self.error_prev != self.error_cur:\n",
    "            self.error_prev = self.initial_steps()\n",
    "            nodes_list = self.nodes()\n",
    "            print(nodes_list)\n",
    "            np.random.shuffle(nodes_list)\n",
    "            for t in nodes_list:\n",
    "                nodes_in_T_t = self.find_leaf_nodes(t)\n",
    "                I = self.construct_I(X, nodes_in_T_t)\n",
    "                self.optimize_node_parallel(t, X[I], y[I])\n",
    "        return self.T\n",
    "\n",
    "    def get_rules(self, feature_names):\n",
    "        tree_ = self.T.tree_\n",
    "        feature_name = [\n",
    "            feature_names[i] if i != _tree.TREE_UNDEFINED else \"undefined!\"\n",
    "            for i in tree_.feature\n",
    "        ]\n",
    "\n",
    "        paths = []\n",
    "        path = []\n",
    "\n",
    "        def recurse(node, path, paths):\n",
    "\n",
    "            if tree_.feature[node] != _tree.TREE_UNDEFINED:\n",
    "                name = feature_name[node]\n",
    "                threshold = tree_.threshold[node]\n",
    "                p1, p2 = list(path), list(path)\n",
    "                p1 += [f\"({name} <= {np.round(threshold, 3)})\"]\n",
    "                recurse(tree_.children_left[node], p1, paths)\n",
    "                p2 += [f\"({name} > {np.round(threshold, 3)})\"]\n",
    "                recurse(tree_.children_right[node], p2, paths)\n",
    "            else:\n",
    "                path += [(tree_.value[node], tree_.n_node_samples[node])]\n",
    "                paths += [path]\n",
    "\n",
    "        recurse(0, path, paths)\n",
    "\n",
    "        # sort by samples count\n",
    "        samples_count = [p[-1][1] for p in paths]\n",
    "        ii = list(np.argsort(samples_count))\n",
    "        print(samples_count)\n",
    "        paths = [paths[i] for i in reversed(ii)]\n",
    "\n",
    "        rules = []\n",
    "        for path in paths:\n",
    "            rule = \"\"\n",
    "\n",
    "            for p in path[:-1]:\n",
    "                if rule != \"\":\n",
    "                    rule += \" & \"\n",
    "                rule += str(p)\n",
    "\n",
    "            rules += [rule]\n",
    "\n",
    "        return rules"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "outputs": [],
   "source": [
    "rule_fit = RuleFitLocalSearch(max_depth=3, min_leaf_size=3, alpha=0.00001)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[19, 44, 52, 11, 15, 50, 31, 28]\n",
      "SSE contributes 99.58717911256245% to the initial loss\n",
      "Complexity contributes 0.41282088743755524%\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "\"None of [Index([  1,   2,   3,   7,   9,  10,  11,  12,  15,  17,\\n       ...\\n       234, 235, 236, 238, 239, 241, 243, 244, 246, 247],\\n      dtype='int64', length=124)] are in the [columns]\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[90], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mrule_fit\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mlocal_search\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[0;32mIn[88], line 126\u001B[0m, in \u001B[0;36mRuleFitLocalSearch.local_search\u001B[0;34m(self, X, y)\u001B[0m\n\u001B[1;32m    124\u001B[0m         nodes_in_T_t \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfind_leaf_nodes(t)\n\u001B[1;32m    125\u001B[0m         I \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconstruct_I(X, nodes_in_T_t)\n\u001B[0;32m--> 126\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39moptimize_node_parallel(t, \u001B[43mX\u001B[49m\u001B[43m[\u001B[49m\u001B[43mI\u001B[49m\u001B[43m]\u001B[49m, y[I])\n\u001B[1;32m    127\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mT\n",
      "File \u001B[0;32m~/Dropbox (MIT)/Uni USA/Poker/Alt. Poker implementation/An-Optimal-RuleFit-Algorithm/lib/python3.10/site-packages/pandas/core/frame.py:3767\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[0;34m(self, key)\u001B[0m\n\u001B[1;32m   3765\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m is_iterator(key):\n\u001B[1;32m   3766\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m-> 3767\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_get_indexer_strict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcolumns\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m)\u001B[49m[\u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m   3769\u001B[0m \u001B[38;5;66;03m# take() does not accept boolean indexers\u001B[39;00m\n\u001B[1;32m   3770\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mgetattr\u001B[39m(indexer, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdtype\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mNone\u001B[39;00m) \u001B[38;5;241m==\u001B[39m \u001B[38;5;28mbool\u001B[39m:\n",
      "File \u001B[0;32m~/Dropbox (MIT)/Uni USA/Poker/Alt. Poker implementation/An-Optimal-RuleFit-Algorithm/lib/python3.10/site-packages/pandas/core/indexes/base.py:5876\u001B[0m, in \u001B[0;36mIndex._get_indexer_strict\u001B[0;34m(self, key, axis_name)\u001B[0m\n\u001B[1;32m   5873\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m   5874\u001B[0m     keyarr, indexer, new_indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reindex_non_unique(keyarr)\n\u001B[0;32m-> 5876\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_raise_if_missing\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkeyarr\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindexer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maxis_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   5878\u001B[0m keyarr \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtake(indexer)\n\u001B[1;32m   5879\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Index):\n\u001B[1;32m   5880\u001B[0m     \u001B[38;5;66;03m# GH 42790 - Preserve name from an Index\u001B[39;00m\n",
      "File \u001B[0;32m~/Dropbox (MIT)/Uni USA/Poker/Alt. Poker implementation/An-Optimal-RuleFit-Algorithm/lib/python3.10/site-packages/pandas/core/indexes/base.py:5935\u001B[0m, in \u001B[0;36mIndex._raise_if_missing\u001B[0;34m(self, key, indexer, axis_name)\u001B[0m\n\u001B[1;32m   5933\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m use_interval_msg:\n\u001B[1;32m   5934\u001B[0m         key \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(key)\n\u001B[0;32m-> 5935\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNone of [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mkey\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m] are in the [\u001B[39m\u001B[38;5;132;01m{\u001B[39;00maxis_name\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m]\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   5937\u001B[0m not_found \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(ensure_index(key)[missing_mask\u001B[38;5;241m.\u001B[39mnonzero()[\u001B[38;5;241m0\u001B[39m]]\u001B[38;5;241m.\u001B[39munique())\n\u001B[1;32m   5938\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnot_found\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not in index\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"None of [Index([  1,   2,   3,   7,   9,  10,  11,  12,  15,  17,\\n       ...\\n       234, 235, 236, 238, 239, 241, 243, 244, 246, 247],\\n      dtype='int64', length=124)] are in the [columns]\""
     ]
    }
   ],
   "source": [
    "rule_fit.local_search(x_train, y_train)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
